---
---

@inproceedings{choi2024explainable,
  title={Explainable Rip Current Detection and Visualization with XAI EigenCAM},
  author={Choi, Juno and Rajendran, Muralidharan and Suh, Yong Cheol},
  booktitle={2024 26th International Conference on Advanced Communications Technology (ICACT)},
  pages={1--6},
  year={2024},
  organization={IEEE},
  bibtex_show={true},
  abstract={Rip currents have long posed a serious threat to beachgoers and swimmers. Despite numerous preventive measures throughout the period, the fatality rate [1] underscores the need for a robust rip current detection system. Recently deep learning models have shown promising results in rip current detection, outperforming traditional methods. However, these models still exhibit some accuracy limitations due to insufficient data distribution. To address this challenge, we incorporate a novel largest dataset [2] comprising over 110,215 Korean coastline images. Through the comparative study of the state-of-the-art models, we aim to analyze the detection accuracy of each model and gain a deeper understanding of their intensity over rip current detection. In comparison to the other rip current datasets, the evaluation results on our proposed dataset demonstrate a remarkable elevation in accuracy, reaching 79.4 mAP. Further, we employ the EigenCAM (Eigen Class Activation Maps) to interpret the intense regions of the rip currents and to gain a deeper comprehension of rip current explainability. This comprehensive analysis marks a significant step toward improving rip current safety and understanding.},
  abbr={IEEE-ICACT},
  doi={https://doi.org/10.23919/ICACT60172.2024.10471913}
}

@article{rajendran2025autoregressive,
  title={Autoregressive multimodal transformer for zero-shot sales forecasting of fashion products with exogenous data},
  author={Rajendran, Muralidharan and Hong, Bonghee},
  journal={Applied Intelligence},
  volume={55},
  number={2},
  pages={1--16},
  year={2025},
  publisher={Springer},
  bibtex_show={true},
  abstract={Predicting future sales volumes of fashion industry products is challenging due to rapid market changes and limited historical sales data for recent products. As traditional forecasting methods and machine learning models often fail to address this problem, we propose a novel autoregressive multimodal transformer architecture to anticipate the sales volume of brand-new apparel items by capturing trends among interrelated attributes. In this paper, we utilize authentic data from a fashion company that includes a limited amount of historical time-series sales data and several influencing factors like product image, textual descriptions, and temporal attributes. To mitigate the data inadequacies, we investigate the impact of integrating exogenous knowledge from an e-tailer site filtered with fashion apparel products. Also, we found that employing the zero-shot forecasting approach further aids in forecasting with minimal time-series sales data. Our approach achieves the values of 1.546 and 16.42 in terms of MAE and WAPE, respectively, by leveraging exogenous data compared to existing benchmark models. This study demonstrates the potential of our autoregressive multimodal transformer to predict sales volumes with more precision, and it highlights the importance of incorporating the zero-shot forecasting approach in the dynamic fashion industry.},
  abbr={App. Intelligence},
  doi={https://doi.org/10.1007/s10489-024-05972-3}
}

@article{muralidharan2022우수논문,
  title={[우수논문] A Deep Learning Application for Forecasting the Time-Series Sales Volume of a Specific Fashion Store Using Online Retailer Data},
  author={Rajendran, Muralidharan and Hong, Bonghee},
  journal={한국정보과학회 학술발표논문집},
  pages={292--294},
  year={2022},
  bibtex_show={true},
  abbr={KIISE-KSC},
  html={https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11224081},
  award={Won Best Paper Award}
}

